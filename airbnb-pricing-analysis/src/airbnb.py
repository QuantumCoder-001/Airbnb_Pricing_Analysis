# -*- coding: utf-8 -*-
"""AirBnb.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1xuKmk-Z1bJSF0wnw_-B2ZrQD45hk6dDT
"""

import pandas as pd

# Load dataset
df = pd.read_csv("/content/drive/MyDrive/airbnb/listings.csv")
print(df.shape)
print(df.info())
print(df.describe())

print(df.isnull().sum().sort_values(ascending=False).head(20))

# 1) Drop rows where price is missing
df = df.dropna(subset=['price']).copy()

# 2) Convert `price` to numeric (handles "$1,234.00", commas, spaces, etc.)
df['price'] = (
    df['price']
      .astype(str)
      .str.replace(r'[^0-9\.]', '', regex=True)   # keep digits and dot only
      .replace({'': pd.NA, '.': pd.NA})
      .astype(float)
)

# 3) Drop any rows where price failed to convert
df = df.dropna(subset=['price'])

to_drop = [
    'calendar_updated',
    'license',
    'host_about',
    'neighborhood_overview',
    'estimated_revenue_l365d'
]
df = df.drop(columns=[c for c in to_drop if c in df.columns])

# 5) Drop exact duplicate rows if any
dups = df.duplicated().sum()
if dups > 0:
    df = df.drop_duplicates()

print("Duplicates removed:", dups)
print("Shape AFTER:", df.shape)

# 6) Re-check top missing columns and confirm price looks good
print("\nTop missing columns after cleanup:")
print(df.isnull().sum().sort_values(ascending=False).head(20))

print("\nPrice summary:")
print(df['price'].describe())

# 1) Remove listings with unrealistic prices
df = df[(df['price'] >= 10) & (df['price'] <= 1000)]

# 2) Remove listings with extremely high minimum nights (likely errors)
if 'minimum_nights' in df.columns:
    df = df[df['minimum_nights'] <= 365]

print("Shape AFTER outlier removal:", df.shape)

# 3) Select relevant columns for pricing analysis
keep_cols = [
    'id', 'name', 'neighbourhood', 'room_type', 'property_type',
    'price', 'minimum_nights', 'availability_365',
    'number_of_reviews', 'review_scores_rating', 'bedrooms'
]

df = df[[c for c in keep_cols if c in df.columns]].copy()

print("Columns now in use:", df.columns.tolist())

# 4) Check remaining missing values
print("\nMissing values after column selection:")
print(df.isnull().sum())

# 1) Handle neighbourhood: fill missing with "Unknown"
if 'neighbourhood' in df.columns:
    df['neighbourhood'] = df['neighbourhood'].fillna('Unknown')

# 2) Handle review_scores_rating: fill with median score
if 'review_scores_rating' in df.columns:
    median_rating = df['review_scores_rating'].median()
    df['review_scores_rating'] = df['review_scores_rating'].fillna(median_rating)

# 3) Handle bedrooms: fill with median number of bedrooms
if 'bedrooms' in df.columns:
    median_bedrooms = df['bedrooms'].median()
    df['bedrooms'] = df['bedrooms'].fillna(median_bedrooms)

# 4) Confirm missing values are handled
print("Remaining missing values:")
print(df.isnull().sum())

import matplotlib.pyplot as plt
import seaborn as sns

# Price distribution
plt.figure(figsize=(8,5))
sns.histplot(df['price'], bins=50, kde=True)
plt.title("Distribution of Airbnb Prices")
plt.xlabel("Price ($)")
plt.ylabel("Count")
plt.show()

plt.figure(figsize=(8,5))
sns.boxplot(x='room_type', y='price', data=df)
plt.title("Price Distribution by Room Type")
plt.ylim(0, 600)   # cap y-axis for visibility
plt.show()

plt.figure(figsize=(10,6))
top_neigh = df.groupby('neighbourhood')['price'].mean().sort_values(ascending=False).head(15)
sns.barplot(x=top_neigh.values, y=top_neigh.index, palette="viridis")
plt.title("Top 15 Neighbourhoods by Average Price")
plt.xlabel("Average Price ($)")
plt.ylabel("Neighbourhood")
plt.show()

plt.figure(figsize=(8,5))
sns.scatterplot(x='review_scores_rating', y='price', data=df, alpha=0.5)
plt.title("Price vs Review Scores")
plt.xlabel("Review Score Rating")
plt.ylabel("Price ($)")
plt.ylim(0, 600)   # limit to improve visibility
plt.show()

# --- Availability vs Price (cleaned categories) ---

# Create bins for availability
def categorize_availability(x):
    if x == 0:
        return "Not Available"
    elif x < 90:
        return "Rarely (<3 months)"
    elif x < 180:
        return "Seasonal (3-6 months)"
    elif x < 365:
        return "Most Year (6-12 months)"
    else:
        return "Full Year (365)"

df['availability_category'] = df['availability_365'].apply(categorize_availability)

# Plot price by availability category
plt.figure(figsize=(8,5))
sns.boxplot(
    x='availability_category',
    y='price',
    data=df,
    order=[
        "Not Available",
        "Rarely (<3 months)",
        "Seasonal (3-6 months)",
        "Most Year (6-12 months)",
        "Full Year (365)"
    ]
)
plt.title("Price by Availability Category")
plt.ylim(0, 600)
plt.xticks(rotation=20)
plt.show()

# --- Correlation Heatmap for numerical features ---

# Select only numeric columns
numeric_df = df.select_dtypes(include=['int64','float64'])

# Compute correlation
corr = numeric_df.corr()

# Plot heatmap
plt.figure(figsize=(8,6))
sns.heatmap(corr, annot=True, fmt=".2f", cmap="coolwarm", cbar=True)
plt.title("Correlation Heatmap (Numerical Features)")
plt.show()

# --- Feature Engineering ---

# Select features for modeling
features = ["neighbourhood", "room_type", "property_type",
            "minimum_nights", "availability_365",
            "number_of_reviews", "review_scores_rating", "bedrooms"]

X = df[features]
y = df["price"]

# One-hot encode categorical variables
X = pd.get_dummies(X, drop_first=True)

print("Shape after encoding:", X.shape)
print("Sample columns:", X.columns[:10])

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score
import numpy as np

# Train-test split (80% train, 20% test)
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# Train model
lr = LinearRegression()
lr.fit(X_train, y_train)

# Predictions
y_pred = lr.predict(X_test)

# Evaluation
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

print("Linear Regression Performance:")
print("RMSE:", rmse)
print("RÂ²:", r2)

from sklearn.linear_model import Ridge, Lasso

# Ridge Regression
ridge = Ridge(alpha=1.0)
ridge.fit(X_train, y_train)
y_pred_ridge = ridge.predict(X_test)

rmse_ridge = np.sqrt(mean_squared_error(y_test, y_pred_ridge))
r2_ridge = r2_score(y_test, y_pred_ridge)

print("Ridge Regression:")
print("RMSE:", rmse_ridge)
print("RÂ²:", r2_ridge)

# Lasso Regression
lasso = Lasso(alpha=0.001, max_iter=10000)
lasso.fit(X_train, y_train)
y_pred_lasso = lasso.predict(X_test)

rmse_lasso = np.sqrt(mean_squared_error(y_test, y_pred_lasso))
r2_lasso = r2_score(y_test, y_pred_lasso)

print("\nLasso Regression:")
print("RMSE:", rmse_lasso)
print("RÂ²:", r2_lasso)

from sklearn.ensemble import RandomForestRegressor

# Random Forest
rf = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)
rf.fit(X_train, y_train)
y_pred_rf = rf.predict(X_test)

rmse_rf = np.sqrt(mean_squared_error(y_test, y_pred_rf))
r2_rf = r2_score(y_test, y_pred_rf)

print("Random Forest Regression:")
print("RMSE:", rmse_rf)
print("RÂ²:", r2_rf)

# --- Feature Importance from Random Forest ---
import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd

# Get feature importances
importances = rf.feature_importances_
feature_names = X.columns

# Sort importances
feat_imp = pd.DataFrame({"feature": feature_names, "importance": importances})
feat_imp = feat_imp.sort_values("importance", ascending=False).head(15)  # top 15

# Plot
plt.figure(figsize=(10,6))
sns.barplot(x="importance", y="feature", data=feat_imp, palette="viridis")
plt.title("Top 15 Feature Importances (Random Forest)")
plt.show()

def recommend_price(model, user_input, df_encoded):
    """
    Predicts optimal Airbnb price based on user inputs.

    model: trained regression model (RandomForestRegressor)
    user_input: dict of feature values (e.g., {"bedrooms": 2, "room_type": "Private room"})
    df_encoded: training DataFrame (used for reference to create dummy vars)
    """
    import pandas as pd

    # Convert input to DataFrame
    input_df = pd.DataFrame([user_input])

    # One-hot encode to match training features
    input_encoded = pd.get_dummies(input_df)
    input_encoded = input_encoded.reindex(columns=df_encoded.columns, fill_value=0)

    # Predict price
    predicted_price = model.predict(input_encoded)[0]

    return round(predicted_price, 2)


# ðŸ”¹ Example usage
user_input = {
    "minimum_nights": 3,
    "availability_365": 200,
    "number_of_reviews": 50,
    "review_scores_rating": 4.5,
    "bedrooms": 2,
    "neighbourhood": "Manhattan",
    "room_type": "Private room",
    "property_type": "Apartment"
}

suggested_price = recommend_price(rf, user_input, X_train)  # rf is your trained Random Forest
print("ðŸ’¡ Suggested Price:", suggested_price)

# Add predicted prices to dataset
df["predicted_price"] = rf.predict(X)

# Save to CSV for Tableau
df.to_csv("airbnb_with_predictions.csv", index=False)

print("âœ… File saved: airbnb_with_predictions.csv")

from google.colab import files
files.download('airbnb_with_predictions.csv')